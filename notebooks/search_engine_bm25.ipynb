{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "962e9a1ea55c4d3d9e6220eb2fe90133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2eeb168e33e948e6bff50df9bc96a828",
              "IPY_MODEL_7c5bce39579e454087cf9fd90dc1d386",
              "IPY_MODEL_edebdde2728841d39cd939a37b51298e"
            ],
            "layout": "IPY_MODEL_8d8e4a431ff343c897636a39fe401a14"
          }
        },
        "2eeb168e33e948e6bff50df9bc96a828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca7d4cdc9ae49d5bc5d480cf44ca70d",
            "placeholder": "​",
            "style": "IPY_MODEL_2b014676868346f9b730714c0c11ef4f",
            "value": "Downloading builder script: 100%"
          }
        },
        "7c5bce39579e454087cf9fd90dc1d386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f2bc2a7b785430b9aad18e4925318b8",
            "max": 5514,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_259b8cac20464e8bbe596b2f97e8ea1c",
            "value": 5514
          }
        },
        "edebdde2728841d39cd939a37b51298e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8217cab9283447a0a676bd4bd73f5ceb",
            "placeholder": "​",
            "style": "IPY_MODEL_55f21563a19e41b7b369e99ba7ec90e1",
            "value": " 5.51k/5.51k [00:00&lt;00:00, 151kB/s]"
          }
        },
        "8d8e4a431ff343c897636a39fe401a14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca7d4cdc9ae49d5bc5d480cf44ca70d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b014676868346f9b730714c0c11ef4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f2bc2a7b785430b9aad18e4925318b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259b8cac20464e8bbe596b2f97e8ea1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8217cab9283447a0a676bd4bd73f5ceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55f21563a19e41b7b369e99ba7ec90e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando as libs relevantes\n",
        "\n",
        "Ao longo deste projeto utilizarei a implementação da `rank_bm25` da Okapi e uma implementação from scratch, o módulo `evaluate` que implementa `trec_eval` da HuggingFace, e também sua dependência `trectools`."
      ],
      "metadata": {
        "id": "KVeSi9nyBNSr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5JNguGrBB5x",
        "outputId": "020502fa-1c45-40bd-ee28-efd892e00ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from rank_bm25) (1.21.6)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (23.0)\n",
            "Collecting huggingface-hub>=0.7.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2023.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Collecting datasets>=2.0.0\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.25.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.24.3)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (3.0.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, huggingface-hub, datasets, evaluate\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.9.0 evaluate-0.4.0 huggingface-hub-0.12.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trectools\n",
            "  Downloading trectools-0.0.49.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.15 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (1.7.3)\n",
            "Collecting sarge>=0.1.1\n",
            "  Downloading sarge-0.1.7.post1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from trectools) (4.9.2)\n",
            "Requirement already satisfied: bs4>=0.0.0.1 in /usr/local/lib/python3.8/dist-packages (from trectools) (0.0.1)\n",
            "Requirement already satisfied: matplotlib>=1.5 in /usr/local/lib/python3.8/dist-packages (from trectools) (3.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4>=0.0.0.1->trectools) (4.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5->trectools) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.15.0->trectools) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.15->trectools) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5->trectools) (1.15.0)\n",
            "Building wheels for collected packages: trectools\n",
            "  Building wheel for trectools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trectools: filename=trectools-0.0.49-py3-none-any.whl size=27140 sha256=70fe629273bd67c53d67039446827ca87f55ec94acf7d4b49695b45f09ac4527\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/cd/17/9a6b28af70445d948c97018b43b9181acd2fdd23e115ee2055\n",
            "Successfully built trectools\n",
            "Installing collected packages: sarge, trectools\n",
            "Successfully installed sarge-0.1.7.post1 trectools-0.0.49\n"
          ]
        }
      ],
      "source": [
        "!pip install rank_bm25\n",
        "!pip install evaluate\n",
        "!pip install trectools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Montando o drive"
      ],
      "metadata": {
        "id": "7gPk6ntCBPrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN8GJHpxBJrZ",
        "outputId": "a96dc10c-08f4-4172-b4fe-1ec50ec6d662"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando as libs pertinentes"
      ],
      "metadata": {
        "id": "pa2bRGiuIiwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "import nltk\n",
        "import json\n",
        "import math\n",
        "from time import time\n",
        "from evaluate import load\n",
        "from rank_bm25 import BM25Okapi\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTmgyaAzBTAH",
        "outputId": "4f2c74b5-c382-4d9d-8389-2c14cb698b39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo DataLoader\n",
        "\n",
        "O DataLoader é uma classe responsável por carregar todos os arquivos relevantes para esta atividade. Sua implementação contém 4 métodos:\n",
        "\n",
        "\n",
        "*   _load_document_set -> Responsável por carregar os documentos do arquivo CISI.ALL\n",
        "*   _load_query_set -> Responsável por carregar os documentos do arquivo CISI.QRY\n",
        "*   _load_relevant_set -> Responsável por carregar os documentos do arquivo CISI.REL\n",
        "*   load -> Responsável por executar os outros métodos e carregar todos os arquivos.\n",
        "\n"
      ],
      "metadata": {
        "id": "wG817769BfVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/Colab Notebooks/IR/data/'"
      ],
      "metadata": {
        "id": "mN5ZSIM3BZtS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoader():\n",
        "    \"\"\"\n",
        "    Class responsible for handling data load. It is implemented specifically for CISI dataset,\n",
        "    but it can be modified to handle other datasets.\n",
        "\n",
        "    Methods:\n",
        "        _load_document_set: responsible for loading the document set (CISI.ALL)\n",
        "            Returns: \n",
        "                document_set: a dict with keys as indexes of documents and values as texts.\n",
        "        _load_query_set: responsible for loading the query set (CISI.QRY)\n",
        "            Returns: \n",
        "                query_set: a dict with keys as indexes of documents and values as texts.\n",
        "        _load_relevant_set: responsible for loading the relevant set (CISI.REL)\n",
        "            Returns: \n",
        "                relevant_set: a dict with keys as indexes of documents and values as list of relevant indexes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, PATH):\n",
        "        self.path = PATH\n",
        "\n",
        "    def _load_document_set(self):\n",
        "        # Getting document set\n",
        "        document_set = {}\n",
        "        doc_id = \"\"\n",
        "        doc_text = \"\"\n",
        "\n",
        "        # Opening file\n",
        "        with open(self.path + 'CISI.ALL') as f:\n",
        "            lines = \"\"\n",
        "            \n",
        "            # Iterating through lines and parsing \n",
        "            for l in f.readlines():\n",
        "                lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "            lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        "\n",
        "        # Getting relevant lines\n",
        "        doc_count = 0\n",
        "        for l in lines:\n",
        "            if l.startswith(\".I\"): # .I stands for index\n",
        "                doc_id = int(l.split(\" \")[1].strip())-1\n",
        "            elif l.startswith(\".X\"): # .X may not be relevant\n",
        "                document_set[doc_id] = doc_text.lstrip(\" \")\n",
        "                doc_id = \"\"\n",
        "                doc_text = \"\"\n",
        "            else: # Concating author, title and text\n",
        "                doc_text += l.strip()[3:] + \" \" \n",
        "        \n",
        "        return document_set\n",
        "\n",
        "\n",
        "    def _load_query_set(self):\n",
        "        # Getting query set\n",
        "        query_set = {}\n",
        "        query_id = \"\"\n",
        "\n",
        "        # Openinig file\n",
        "        with open(self.path + 'CISI.QRY') as f:\n",
        "            lines = \"\"\n",
        "\n",
        "            # Iterating through lines and parsing\n",
        "            for l in f.readlines():\n",
        "                lines += \"\\n\" + l.strip() if l.startswith(\".\") else \" \" + l.strip()\n",
        "            lines = lines.lstrip(\"\\n\").split(\"\\n\")\n",
        "            \n",
        "        # Getting relevant lines\n",
        "        for l in lines:\n",
        "            if l.startswith(\".I\"): # .I stands for index\n",
        "                query_id = int(l.split(\" \")[1].strip()) -1\n",
        "            elif l.startswith(\".W\"): # .W stands for the query text\n",
        "                query_set[query_id] = l.strip()[3:]\n",
        "                query_id = \"\"\n",
        "\n",
        "        return query_set\n",
        "\n",
        "    def _load_relevant_set(self):\n",
        "        # Getting relevant set\n",
        "        relevant_set = {}\n",
        "\n",
        "        # Opening file\n",
        "        with open(PATH + 'CISI.REL') as f:\n",
        "\n",
        "            # Iterating through lines and parsing \n",
        "            for l in f.readlines():\n",
        "                qry_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]) -1\n",
        "                doc_id = int(l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1])-1\n",
        "                if qry_id in relevant_set:\n",
        "                    relevant_set[qry_id].append(doc_id)\n",
        "                else:\n",
        "                    relevant_set[qry_id] = []\n",
        "                    relevant_set[qry_id].append(doc_id)\n",
        "\n",
        "        return relevant_set\n",
        "\n",
        "\n",
        "    def load(self):\n",
        "        document_set = self._load_document_set()\n",
        "        query_set    = self._load_query_set()\n",
        "        relevant_set = self._load_relevant_set()\n",
        "\n",
        "        return document_set, query_set, relevant_set"
      ],
      "metadata": {
        "id": "PlitaS_oBhMx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(PATH)"
      ],
      "metadata": {
        "id": "FbxXbJPZBoKE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_set, query_set, relevant_set = dataloader.load()"
      ],
      "metadata": {
        "id": "GcZQvc6JBqYR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "qj7KyOwrBrUB",
        "outputId": "2aefff0d-cd68-45c8-b563-76e25be70b68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7TyIlHfUBsWb",
        "outputId": "997790a9-b551-4ed7-d762-d269a37720d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L2PTirYBtti",
        "outputId": "79c9e536-90a9-4439-bc08-0d0c1099cfd7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[27,\n",
              " 34,\n",
              " 37,\n",
              " 41,\n",
              " 42,\n",
              " 51,\n",
              " 64,\n",
              " 75,\n",
              " 85,\n",
              " 149,\n",
              " 188,\n",
              " 191,\n",
              " 192,\n",
              " 194,\n",
              " 214,\n",
              " 268,\n",
              " 290,\n",
              " 319,\n",
              " 428,\n",
              " 464,\n",
              " 465,\n",
              " 481,\n",
              " 482,\n",
              " 509,\n",
              " 523,\n",
              " 540,\n",
              " 575,\n",
              " 581,\n",
              " 588,\n",
              " 602,\n",
              " 649,\n",
              " 679,\n",
              " 710,\n",
              " 721,\n",
              " 725,\n",
              " 782,\n",
              " 812,\n",
              " 819,\n",
              " 867,\n",
              " 868,\n",
              " 893,\n",
              " 1161,\n",
              " 1163,\n",
              " 1194,\n",
              " 1195,\n",
              " 1280]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lista com queries sem documentos relevantes\n",
        "\n",
        "Existem algumas queries que não tem correspondência no arquivo de documentos relevantes. Vou deixá-las explícitas em uma variável para utilizar posteriormente. A ideia é não calcular métricas para essas queries."
      ],
      "metadata": {
        "id": "EAUobzHVB5YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries_with_no_relevant_docs = np.setdiff1d(list(query_set.keys()),list(relevant_set.keys()))"
      ],
      "metadata": {
        "id": "M59_vzeUBvO_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limpando e criando o corpus\n",
        "\n",
        "A etapa de limpeza de dados é muito importante. É uma etapa customizável, uma vez que podemos escolher diferentes estratégias de limpeza dos textos.\n",
        "Aqui, escolhi o seguinte caminho:\n",
        "\n",
        "- retirar acentuação e caractéres especiais;\n",
        "- aplicar .lower() em todas as palavras;\n",
        "- tokenização;\n",
        "- remoção de stopwords da língua inglesa;\n",
        "- aplicação de stemmer (extração dos núcleos das palavras)."
      ],
      "metadata": {
        "id": "R3K_HXFaCAM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PreProcessing:\n",
        "    \"\"\"\n",
        "    Class that preprocess all corpus data\n",
        "    Methods:\n",
        "        _remove_special_char: removes special characters based on string.punctuation module\n",
        "            Args:\n",
        "                input_string: string to clean\n",
        "            Returns:\n",
        "                string without punctuations\n",
        "        _preprocess_string: Apply _remove_special_char followed by tokenization and stem, removing stopwords\n",
        "            Args:\n",
        "                input_string: string to clean\n",
        "            Returns:\n",
        "                tokens: list of cleaned tokens\n",
        "        preprocess_corpus: Apply _preprocess string into a set of documents\n",
        "            Args:\n",
        "                corpus_set: a dict containing the texts to clean in its values\n",
        "            Returns:\n",
        "                a list of cleaned and tokenized texts\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, stopwords: list, stemmer):\n",
        "        self.stopwords = stopwords\n",
        "        self.stemmer   = stemmer \n",
        "\n",
        "    def _remove_special_char(self, input_string: str):\n",
        "        return input_string.translate(str.maketrans('','', string.punctuation)).lower()\n",
        "\n",
        "    def _preprocess_string(self, input_string: str):\n",
        "     \n",
        "        # Removing special characters\n",
        "        txt = self._remove_special_char(input_string)\n",
        "\n",
        "        # creating tokens\n",
        "        tokens = nltk.tokenize.word_tokenize(txt) \n",
        "        \n",
        "        # removing stopwords and applying stemmer\n",
        "        tokens = [self.stemmer.stem(tk) for tk in tokens if tk not in self.stopwords]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "    def preprocess_corpus(self, corpus_set: dict):\n",
        "        return [self._preprocess_string(txt) for txt in corpus_set.values()]"
      ],
      "metadata": {
        "id": "wBP4l9UU288m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the stemmer and stopwords list\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# Applying preprocessing class to documents and queries\n",
        "preprocess = PreProcessing(stopwords = stopwords, stemmer = stemmer)\n",
        "document_corpus = preprocess.preprocess_corpus(document_set)\n",
        "query_corpus    = preprocess.preprocess_corpus(query_set)"
      ],
      "metadata": {
        "id": "hkfJTSZLCFol"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A mesma limpeza que é aplicada aos documentos deve ser aplicada às queries."
      ],
      "metadata": {
        "id": "yYEPD9OqpDcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classe BM25 from scratch"
      ],
      "metadata": {
        "id": "O-yzFqdzE9hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BM25:\n",
        "    \"\"\"\n",
        "    Implementation of BM25 algorithm. It computes the term frequencies, document frequencies\n",
        "    and scores for a given set of documents and query parameters.\n",
        "    Methods:\n",
        "        fit: given a set of corpus, it computes all the necessary statistics to \n",
        "            get bm25 matching scores \n",
        "        _score: computes a single score based on a query and an index\n",
        "        get_scores: computes all scores based on a query and the given corpus\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, k1=1.5, b=0.75):\n",
        "        self.b = b\n",
        "        self.k1 = k1\n",
        "\n",
        "    def fit(self, corpus):\n",
        "        \"\"\"\n",
        "        Function that fits the statistics that are required to calculate BM25 ranking\n",
        "        score using a given corpus.\n",
        "\n",
        "        Args:\n",
        "            corpus : list[list[str]]\n",
        "                Each element in the list represents a document, and each document\n",
        "                is a list of the terms.\n",
        "        Returns:\n",
        "            self\n",
        "        \"\"\"\n",
        "        tf = []\n",
        "        df = {}\n",
        "        idf = {}\n",
        "        doc_len = []\n",
        "        corpus_size = 0\n",
        "        for document in corpus:\n",
        "            corpus_size += 1\n",
        "            doc_len.append(len(document))\n",
        "\n",
        "            # compute tf (term frequency) per document\n",
        "            frequencies = {}\n",
        "            for term in document:\n",
        "                term_count = frequencies.get(term, 0) + 1\n",
        "                frequencies[term] = term_count\n",
        "\n",
        "            tf.append(frequencies)\n",
        "\n",
        "            # compute df (document frequency) per term\n",
        "            for term, _ in frequencies.items():\n",
        "                df_count = df.get(term, 0) + 1\n",
        "                df[term] = df_count\n",
        "\n",
        "        # compute the inverse document frequency\n",
        "        for term, freq in df.items():\n",
        "            idf[term] = math.log(1 + (corpus_size - freq + 0.5) / (freq + 0.5))\n",
        "\n",
        "        self.tf_ = tf\n",
        "        self.df_ = df\n",
        "        self.idf_ = idf\n",
        "        self.doc_len_ = doc_len\n",
        "        self.corpus_ = corpus\n",
        "        self.corpus_size_ = corpus_size\n",
        "        self.avg_doc_len_ = sum(doc_len) / corpus_size\n",
        "        return self\n",
        "\n",
        "    def _score(self, query, index):\n",
        "        \"\"\"\n",
        "        Function that computes a score based on the query and the index\n",
        "        Args:\n",
        "            query: user's query\n",
        "            index: the index of the query\n",
        "        Returns:\n",
        "            score: score of the given query\n",
        "        \"\"\"\n",
        "        score = 0.0\n",
        "\n",
        "        doc_len = self.doc_len_[index]\n",
        "        frequencies = self.tf_[index]\n",
        "        for term in query:\n",
        "            if term not in frequencies:\n",
        "                continue\n",
        "\n",
        "            freq = frequencies[term]\n",
        "            numerator = self.idf_[term] * freq * (self.k1 + 1)\n",
        "            denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len_)\n",
        "            score += (numerator / denominator)\n",
        "\n",
        "        return score\n",
        "\n",
        "    def get_scores(self, query):\n",
        "        \"\"\"\n",
        "        Function that get scores for all the documents in the corpus\n",
        "        Args:\n",
        "            query: input query\n",
        "        Returns:\n",
        "            scores: a list of all the scores\n",
        "        \"\"\"\n",
        "        scores = [self._score(query, index) for index in range(self.corpus_size_)]\n",
        "        return scores"
      ],
      "metadata": {
        "id": "9N9BbLcfFAaO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição da classe de `SearchEngine`\n",
        "\n",
        "Nesta etapa foi implementada uma classe para lidar com toda a lógica de Search Engine, desde o carregamento dos dados, definição do algorítmo de busca (aqui foi usado apenas BM25, mas a classe foi pensada para ser agnóstica a algoritmo) e cálculo de métricas."
      ],
      "metadata": {
        "id": "r0Ms8jMECcQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def timer_func(func):\n",
        "    # This function shows the execution time of \n",
        "    # the function object passed\n",
        "    def wrap_func(*args, **kwargs):\n",
        "        t1 = time()\n",
        "        result = func(*args, **kwargs)\n",
        "        t2 = time()\n",
        "        print(f'Function {func.__name__!r} executed in {(t2-t1):.4f}s')\n",
        "        return result\n",
        "    return wrap_func\n",
        "\n",
        "\n",
        "class SearchEngine:\n",
        "    \"\"\"\n",
        "    This class implements all the logic for a search engine, since loading of data to\n",
        "    preprocessing, tokenization, searching with a given algorithm, and valuation following\n",
        "    the trec_eval framework for metrics extraction.\n",
        "    Methods:\n",
        "        _load_data: given a DataLoader object, performs its methods for data loading\n",
        "        _preprocess: given a PreProcessing object, perfoms its methods for cleaning and tokenization\n",
        "        _fit: given an algorithm (either Okapi or BM25), fits to the tokenized corpus\n",
        "        _results_from_query: given and index and a tokenized query, searches in \n",
        "            the entire corpus, scoring documents and retrieving relevant matches\n",
        "        _data_format_trec_eval: formats relevant set and query results in order to fit the\n",
        "            trec_eval API.\n",
        "        _extract_metrics: performs metrics extractions given by the trec_eval API.\n",
        "        _search: given all the query set, performs the _results_from_query method.\n",
        "        run: runs the entire pipeline returning metrics and a set of retrieved documents.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataloader, preprocessing, algorithm, trec_eval):\n",
        "        self.dataloader    = dataloader\n",
        "        self.preprocessing = preprocessing\n",
        "        self.algorithm     = algorithm\n",
        "        self.trec_eval     = trec_eval\n",
        "\n",
        "    @timer_func\n",
        "    def _load_data(self):\n",
        "        \"\"\"\n",
        "        Function responsible for loading all data based on the DataLoader object provided.\n",
        "        \"\"\"\n",
        "        data = self.dataloader.load()\n",
        "\n",
        "        self.document_set = data[0]\n",
        "        self.query_set    = data[1]\n",
        "        self.relevant_set = data[2]\n",
        "        self.queries_with_no_relevant_docs = np.setdiff1d(list(self.query_set.keys()),list(self.relevant_set.keys()))\n",
        "\n",
        "    @timer_func\n",
        "    def _preprocess(self):\n",
        "        \"\"\"\n",
        "        Function responsible for preprocess and create document and query corpus\n",
        "        based on the PreProcessing object provided.\n",
        "        \"\"\"\n",
        "\n",
        "        self.document_corpus = self.preprocessing.preprocess_corpus(self.document_set)\n",
        "        self.query_corpus    = self.preprocessing.preprocess_corpus(self.query_set)\n",
        "\n",
        "\n",
        "    @timer_func\n",
        "    def _fit(self):\n",
        "        \"\"\" \n",
        "        If algorithm has the \"fit\" attribute, it is the scratch implementation,\n",
        "        otherwise it is the okapi implementation.\n",
        "        This function can generalize as long as the algorithm follows this syntax.\n",
        "        \"\"\"\n",
        "        if hasattr(self.algorithm, 'fit'):\n",
        "            self.algorithm = self.algorithm.fit(self.document_corpus)\n",
        "        else:\n",
        "            self.algorithm = self.algorithm(self.document_corpus)\n",
        "\n",
        "\n",
        "    def _results_from_query(self, idx, tokenized_query):\n",
        "        \"\"\"Return an ordered array of relevant documents returned by query_id\n",
        "\n",
        "        Args:\n",
        "            tokenized_query: tokenized query to submit to algorithm\n",
        "            idx: index of tokenized query\n",
        "            algorithm: indexed corpus\n",
        "        Returns:\n",
        "            sorted_masked_relevance_results: sorted relevance array of documents\n",
        "            metrics: trec_eval metrics\n",
        "        \"\"\"    \n",
        "        relevant_docs = []\n",
        "\n",
        "        # Retrieving relevant document\n",
        "        if idx in self.relevant_set:\n",
        "            relevant_docs = self.relevant_set[idx]\n",
        "\n",
        "        # Scoring query using algorithm\n",
        "        scores = self.algorithm.get_scores(tokenized_query)\n",
        "\n",
        "        # Creating a masked relevant documents \n",
        "        # of 1's and 0's for documents in the relevant set\n",
        "        masked_relevant_docs = np.zeros(len(scores))\n",
        "        masked_relevant_docs[relevant_docs] = 1\n",
        "\n",
        "        # Getting indexes of most relevant retrieved documents\n",
        "        most_relevant_retrieved_docs = np.argsort([-1*x for x in scores])\n",
        "\n",
        "        # trec_eval format\n",
        "        qrel, run = self._data_format_trec_eval(idx, masked_relevant_docs, most_relevant_retrieved_docs, scores)\n",
        "\n",
        "        # Getting metrics\n",
        "        metrics = self._extract_metrics(qrel, run)\n",
        "\n",
        "        return most_relevant_retrieved_docs, metrics\n",
        "\n",
        "    @timer_func\n",
        "    def retrieve_docs_from_query(self, query, n=10):\n",
        "        \"\"\"\n",
        "        Function that takes an user's query and retrieved n documents\n",
        "        Args:\n",
        "            query: user's query (string)\n",
        "            n: number of documents to retrieve\n",
        "        Returns:\n",
        "            retrieved_docs: documents that the algorithms matched\n",
        "        \"\"\"\n",
        "\n",
        "        # preprocess user's query\n",
        "        tokenized_query = self.preprocessing._preprocess_string(query)\n",
        "\n",
        "        # fitting algorithm \n",
        "        try:\n",
        "            # if not fitted, must fit\n",
        "            self._fit()\n",
        "        except:\n",
        "            # if fitted, just pass\n",
        "            pass\n",
        "\n",
        "        # Scoring query using algorithm\n",
        "        scores = self.algorithm.get_scores(tokenized_query)\n",
        "\n",
        "        # Getting indexes of most relevant retrieved documents\n",
        "        most_relevant_retrieved_docs = np.argsort([-1*x for x in scores])\n",
        "\n",
        "        # Getting retrieved docs\n",
        "        retrieved_docs = [self.document_set[i] for i in most_relevant_retrieved_docs[:n]]\n",
        "\n",
        "        return retrieved_docs\n",
        "\n",
        "\n",
        "\n",
        "    def _data_format_trec_eval_bkp(self, idx, masked_relevant_docs, most_relevant_retrieved_docs, scores):\n",
        "        \"\"\"\n",
        "        #####################\n",
        "        #### DEPRECATED #####\n",
        "        #####################\n",
        "\n",
        "        Function that transforms a set of scores, retrieved and relevant documents\n",
        "        into trec_eval format used by HuggingFace evaluate module.\n",
        "        Args:\n",
        "            idx: index of document\n",
        "            masked_relevant_docs: list of relevant documents\n",
        "            most_relevant_retrieved_docs: list of retrieved documents\n",
        "            scores: list with BM25 scores\n",
        "        Returns:\n",
        "            qrel: dict with relevant documents in trec_eval format\n",
        "            run: dict with retrieved docouments and scores in trec_eval format.\n",
        "        ## SOURCE: https://huggingface.co/spaces/evaluate-metric/trec_eval\n",
        "        \"\"\"\n",
        "        \n",
        "        N = len(masked_relevant_docs)\n",
        "\n",
        "        qrel = {\n",
        "            'query': [idx] * N,\n",
        "            'q0': ['q0'] * N,\n",
        "            \"docid\": [str(x) for x in masked_relevant_docs],\n",
        "            \"rel\": [str(x) for x in masked_relevant_docs]\n",
        "        }\n",
        "\n",
        "        run = {\n",
        "            \"query\": [idx] * N,\n",
        "            \"q0\": [\"q0\"] * N,\n",
        "            \"docid\": [str(x) for x in list(most_relevant_retrieved_docs[:N])],\n",
        "            \"rank\": list(range(N)),\n",
        "            \"score\": sorted(scores)[::-1][:N],\n",
        "            \"system\": [\"test\"] * N\n",
        "        }\n",
        "\n",
        "        return qrel, run\n",
        "\n",
        "\n",
        "    def _data_format_trec_eval(self, idx, masked_relevant_docs, most_relevant_retrieved_docs, scores):\n",
        "        \"\"\"\n",
        "        Function that transforms a set of scores, retrieved and relevant documents\n",
        "        into trec_eval format used by HuggingFace evaluate module.\n",
        "        Args:\n",
        "            idx: index of document\n",
        "            masked_relevant_docs: list of relevant documents\n",
        "            most_relevant_retrieved_docs: list of retrieved documents\n",
        "            scores: list with BM25 scores\n",
        "        Returns:\n",
        "            qrel: dict with relevant documents in trec_eval format\n",
        "            run: dict with retrieved docouments and scores in trec_eval format.\n",
        "        ## SOURCE: https://huggingface.co/spaces/evaluate-metric/trec_eval\n",
        "        \"\"\"\n",
        "        \n",
        "        N_REL_DOCS = len(masked_relevant_docs)\n",
        "        N_RET_DOCS = len(most_relevant_retrieved_docs)\n",
        "\n",
        "        qrel = {\n",
        "            'query': [idx] * N_REL_DOCS,\n",
        "            'q0': ['q0'] * N_REL_DOCS,\n",
        "            \"docid\": [str(int(x)) for x in range(N_REL_DOCS)],\n",
        "            \"rel\": [str(int(x)) for x in masked_relevant_docs]\n",
        "        }\n",
        "\n",
        "        run = {\n",
        "            \"query\": [idx] * N_RET_DOCS,\n",
        "            \"q0\": [\"q0\"] * N_RET_DOCS,\n",
        "            \"docid\": [str(x) for x in list(most_relevant_retrieved_docs[:N_RET_DOCS])],\n",
        "            \"rank\": list(range(N_RET_DOCS)),\n",
        "            \"score\": sorted(scores)[::-1][:N_RET_DOCS],\n",
        "            \"system\": [\"test\"] * N_RET_DOCS\n",
        "        }\n",
        "\n",
        "        return qrel, run\n",
        "\n",
        "\n",
        "    def _extract_metrics(self, qrel, run):\n",
        "        \"\"\"\n",
        "        Function that extract trec_eval metrics from qrel and run\n",
        "        Args:\n",
        "            qrel: dict with relevant documents in trec_eval format\n",
        "            run: dict with retrieved docouments and scores in trec_eval format\n",
        "        Returns:\n",
        "            metrics: dict with trec_eval metrics.\n",
        "        \"\"\"\n",
        "        return self.trec_eval.compute(references=[qrel], predictions=[run])\n",
        "\n",
        "    @timer_func\n",
        "    def _search(self):\n",
        "        \"\"\"\n",
        "        Function that execute all queries in the document set and outputs\n",
        "        both the retrieved documents and metrics \n",
        "        \"\"\"\n",
        "        # Running search for all queries\n",
        "        output = [\n",
        "              self._results_from_query(idx, tokenized_query) \n",
        "              for idx, tokenized_query in enumerate(self.query_corpus)\n",
        "              if idx not in self.queries_with_no_relevant_docs\n",
        "        ]\n",
        "\n",
        "        # Extracting most relevant documents and metrics\n",
        "        most_relevant_retrieved_docs = [x[0] for x in output]\n",
        "        metrics                      = [x[1] for x in output]\n",
        "\n",
        "        return most_relevant_retrieved_docs, pd.DataFrame(metrics)\n",
        "\n",
        "    @timer_func\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Function responsible for run all steps of the pipeline for information retrieval.\n",
        "        \"\"\"\n",
        "        # Loading data\n",
        "        self._load_data()\n",
        "\n",
        "        # Preprocess data\n",
        "        self._preprocess()\n",
        "\n",
        "        # Fitting algorithm\n",
        "        self._fit()\n",
        "\n",
        "        # Searching \n",
        "        most_relevant_retrieved_docs, df_metrics = self._search()\n",
        "\n",
        "        return most_relevant_retrieved_docs, df_metrics\n"
      ],
      "metadata": {
        "id": "KTYcbl7LCwq_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rodando o pipeline completo\n",
        "\n",
        "- Definição das classes cujo `SearchEngine` depende\n",
        "  - `DataLoader`\n",
        "    - depende do `PATH`\n",
        "  - `PreProcessing`\n",
        "    - depende das `stopwords` e do `stemmer`\n",
        "  - `Algorithm`\n",
        "    - `Okapi` ou `Scratch`\n",
        "  - `trec_eval`"
      ],
      "metadata": {
        "id": "e1d7GDggERtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/IR/data/' \n",
        "dataloader = DataLoader(PATH)\n",
        "\n",
        "# PreProcessing\n",
        "stemmer = nltk.stem.PorterStemmer()\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "preprocessing = PreProcessing(stopwords = stopwords, stemmer = stemmer)\n",
        "\n",
        "# Algorithm\n",
        "algo1 = BM25Okapi\n",
        "algo2 = BM25()\n",
        "\n",
        "# trec eval\n",
        "trec_eval = load(\"trec_eval\")\n",
        "\n",
        "# SearchEngine1\n",
        "search_engine_1 = SearchEngine(dataloader, preprocessing, algo1, trec_eval)\n",
        "most_relevant_docs_1, df_metrics_1 = search_engine_1.run()\n",
        "\n",
        "# SearchEngine2\n",
        "search_engine_2 = SearchEngine(dataloader, preprocessing, algo2, trec_eval)\n",
        "most_relevant_docs_2, df_metrics_2 = search_engine_2.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "962e9a1ea55c4d3d9e6220eb2fe90133",
            "2eeb168e33e948e6bff50df9bc96a828",
            "7c5bce39579e454087cf9fd90dc1d386",
            "edebdde2728841d39cd939a37b51298e",
            "8d8e4a431ff343c897636a39fe401a14",
            "eca7d4cdc9ae49d5bc5d480cf44ca70d",
            "2b014676868346f9b730714c0c11ef4f",
            "8f2bc2a7b785430b9aad18e4925318b8",
            "259b8cac20464e8bbe596b2f97e8ea1c",
            "8217cab9283447a0a676bd4bd73f5ceb",
            "55f21563a19e41b7b369e99ba7ec90e1"
          ]
        },
        "id": "e_4nJNggD-zj",
        "outputId": "40f16757-01ad-4582-901c-2bee95550484"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.51k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "962e9a1ea55c4d3d9e6220eb2fe90133"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function '_load_data' executed in 0.0867s\n",
            "Function '_preprocess' executed in 3.8765s\n",
            "Function '_fit' executed in 0.0630s\n",
            "Function '_search' executed in 41.1351s\n",
            "Function 'run' executed in 45.1619s\n",
            "Function '_load_data' executed in 0.0745s\n",
            "Function '_preprocess' executed in 5.2036s\n",
            "Function '_fit' executed in 0.0950s\n",
            "Function '_search' executed in 39.8502s\n",
            "Function 'run' executed in 45.2258s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verificando métrics:\n",
        "# Okapi vs BM25\n",
        "\n",
        "- Mean average precision; \n",
        "- Geometric mean average precision;\n",
        "- Binary preference score;\n",
        "- Precision@R;\n",
        "- Reciprocal Rank."
      ],
      "metadata": {
        "id": "WhmaYklPqGLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set1 = [\n",
        "    'map',\n",
        "    'gm_map',\n",
        "    'bpref',\n",
        "    'Rprec',\n",
        "    'recip_rank'\n",
        "]"
      ],
      "metadata": {
        "id": "Yltu0kkWqdB6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics_1[set1].describe().merge(\n",
        "    df_metrics_2[set1].describe(), \n",
        "    how='left', \n",
        "    left_index=True, \n",
        "    right_index=True, \n",
        "    suffixes=('_Okapi', '_Scratch')\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ZQ1l2Q0nql2W",
        "outputId": "6e848997-c7d8-4645-83b8-2bb16f1df873"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       map_Okapi  gm_map_Okapi  bpref_Okapi  Rprec_Okapi  recip_rank_Okapi  \\\n",
              "count  76.000000     76.000000    76.000000    76.000000         76.000000   \n",
              "mean    0.225431      0.225431     0.202589     0.245756          0.661638   \n",
              "std     0.157095      0.157095     0.154056     0.160005          0.372463   \n",
              "min     0.011458      0.011458     0.000000     0.000000          0.013889   \n",
              "25%     0.109605      0.109605     0.083363     0.142143          0.333333   \n",
              "50%     0.196504      0.196504     0.187077     0.250000          1.000000   \n",
              "75%     0.308895      0.308895     0.276886     0.339112          1.000000   \n",
              "max     0.833584      0.833584     0.833333     0.833333          1.000000   \n",
              "\n",
              "       map_Scratch  gm_map_Scratch  bpref_Scratch  Rprec_Scratch  \\\n",
              "count    76.000000       76.000000      76.000000      76.000000   \n",
              "mean      0.224083        0.224083       0.201311       0.246825   \n",
              "std       0.154845        0.154845       0.146955       0.152068   \n",
              "min       0.011614        0.011614       0.000000       0.000000   \n",
              "25%       0.104506        0.104506       0.090604       0.145089   \n",
              "50%       0.201266        0.201266       0.179778       0.250000   \n",
              "75%       0.311406        0.311406       0.283473       0.351972   \n",
              "max       0.780052        0.780052       0.740741       0.722222   \n",
              "\n",
              "       recip_rank_Scratch  \n",
              "count           76.000000  \n",
              "mean             0.657520  \n",
              "std              0.376336  \n",
              "min              0.014286  \n",
              "25%              0.333333  \n",
              "50%              1.000000  \n",
              "75%              1.000000  \n",
              "max              1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23a70272-d83e-409b-b20c-6c7cbdf67829\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>map_Okapi</th>\n",
              "      <th>gm_map_Okapi</th>\n",
              "      <th>bpref_Okapi</th>\n",
              "      <th>Rprec_Okapi</th>\n",
              "      <th>recip_rank_Okapi</th>\n",
              "      <th>map_Scratch</th>\n",
              "      <th>gm_map_Scratch</th>\n",
              "      <th>bpref_Scratch</th>\n",
              "      <th>Rprec_Scratch</th>\n",
              "      <th>recip_rank_Scratch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.225431</td>\n",
              "      <td>0.225431</td>\n",
              "      <td>0.202589</td>\n",
              "      <td>0.245756</td>\n",
              "      <td>0.661638</td>\n",
              "      <td>0.224083</td>\n",
              "      <td>0.224083</td>\n",
              "      <td>0.201311</td>\n",
              "      <td>0.246825</td>\n",
              "      <td>0.657520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.157095</td>\n",
              "      <td>0.157095</td>\n",
              "      <td>0.154056</td>\n",
              "      <td>0.160005</td>\n",
              "      <td>0.372463</td>\n",
              "      <td>0.154845</td>\n",
              "      <td>0.154845</td>\n",
              "      <td>0.146955</td>\n",
              "      <td>0.152068</td>\n",
              "      <td>0.376336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.011458</td>\n",
              "      <td>0.011458</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013889</td>\n",
              "      <td>0.011614</td>\n",
              "      <td>0.011614</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.109605</td>\n",
              "      <td>0.109605</td>\n",
              "      <td>0.083363</td>\n",
              "      <td>0.142143</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.104506</td>\n",
              "      <td>0.104506</td>\n",
              "      <td>0.090604</td>\n",
              "      <td>0.145089</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.196504</td>\n",
              "      <td>0.196504</td>\n",
              "      <td>0.187077</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.201266</td>\n",
              "      <td>0.201266</td>\n",
              "      <td>0.179778</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.308895</td>\n",
              "      <td>0.308895</td>\n",
              "      <td>0.276886</td>\n",
              "      <td>0.339112</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.311406</td>\n",
              "      <td>0.311406</td>\n",
              "      <td>0.283473</td>\n",
              "      <td>0.351972</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.833584</td>\n",
              "      <td>0.833584</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.780052</td>\n",
              "      <td>0.780052</td>\n",
              "      <td>0.740741</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23a70272-d83e-409b-b20c-6c7cbdf67829')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-23a70272-d83e-409b-b20c-6c7cbdf67829 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-23a70272-d83e-409b-b20c-6c7cbdf67829');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precision"
      ],
      "metadata": {
        "id": "gp57FiuQqpFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision_cols = [\n",
        "    'P@5',\n",
        "    'P@10',\n",
        "    'P@15',\n",
        "    'P@20',\n",
        "    'P@30',\n",
        "    'P@100',\n",
        "    'P@200',\n",
        "    'P@500',\n",
        "    'P@1000',\n",
        "]"
      ],
      "metadata": {
        "id": "8GkoS3hGlnQg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics_1[precision_cols].describe().merge(\n",
        "    df_metrics_2[precision_cols].describe(), \n",
        "    how='left', \n",
        "    left_index=True, \n",
        "    right_index=True, \n",
        "    suffixes=('_Okapi', '_Scratch')\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "-Z0UUgv9GNh8",
        "outputId": "83f5d153-05fa-431e-c37b-c4ef323da261"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       P@5_Okapi  P@10_Okapi  P@15_Okapi  P@20_Okapi  P@30_Okapi  P@100_Okapi  \\\n",
              "count  76.000000   76.000000   76.000000   76.000000   76.000000    76.000000   \n",
              "mean    0.410526    0.369737    0.314035    0.283553    0.239035     0.147237   \n",
              "std     0.291926    0.252465    0.209922    0.193630    0.166568     0.113356   \n",
              "min     0.000000    0.000000    0.000000    0.000000    0.000000     0.010000   \n",
              "25%     0.200000    0.175000    0.133333    0.150000    0.100000     0.060000   \n",
              "50%     0.400000    0.400000    0.333333    0.250000    0.200000     0.120000   \n",
              "75%     0.600000    0.600000    0.466667    0.412500    0.366667     0.192500   \n",
              "max     1.000000    0.900000    0.800000    0.750000    0.566667     0.500000   \n",
              "\n",
              "       P@200_Okapi  P@500_Okapi  P@1000_Okapi  P@5_Scratch  P@10_Scratch  \\\n",
              "count    76.000000    76.000000     76.000000    76.000000     76.000000   \n",
              "mean      0.105132     0.060947      0.038000     0.423684      0.356579   \n",
              "std       0.083570     0.052218      0.032844     0.293879      0.239074   \n",
              "min       0.005000     0.002000      0.001000     0.000000      0.000000   \n",
              "25%       0.040000     0.022000      0.012750     0.200000      0.175000   \n",
              "50%       0.090000     0.048000      0.029500     0.400000      0.300000   \n",
              "75%       0.135000     0.082500      0.049250     0.600000      0.525000   \n",
              "max       0.380000     0.218000      0.134000     1.000000      0.900000   \n",
              "\n",
              "       P@15_Scratch  P@20_Scratch  P@30_Scratch  P@100_Scratch  P@200_Scratch  \\\n",
              "count     76.000000     76.000000     76.000000      76.000000      76.000000   \n",
              "mean       0.327193      0.289474      0.241228       0.149079       0.105921   \n",
              "std        0.215868      0.198211      0.167320       0.110395       0.082546   \n",
              "min        0.000000      0.000000      0.000000       0.010000       0.005000   \n",
              "25%        0.133333      0.150000      0.100000       0.060000       0.043750   \n",
              "50%        0.300000      0.250000      0.200000       0.140000       0.087500   \n",
              "75%        0.466667      0.450000      0.366667       0.202500       0.141250   \n",
              "max        0.800000      0.650000      0.633333       0.430000       0.380000   \n",
              "\n",
              "       P@500_Scratch  P@1000_Scratch  \n",
              "count      76.000000       76.000000  \n",
              "mean        0.061632        0.038105  \n",
              "std         0.051723        0.032929  \n",
              "min         0.002000        0.001000  \n",
              "25%         0.022000        0.012750  \n",
              "50%         0.049000        0.029500  \n",
              "75%         0.085000        0.049000  \n",
              "max         0.202000        0.134000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7b5fb9e-7129-45e4-810a-96e11297cf5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P@5_Okapi</th>\n",
              "      <th>P@10_Okapi</th>\n",
              "      <th>P@15_Okapi</th>\n",
              "      <th>P@20_Okapi</th>\n",
              "      <th>P@30_Okapi</th>\n",
              "      <th>P@100_Okapi</th>\n",
              "      <th>P@200_Okapi</th>\n",
              "      <th>P@500_Okapi</th>\n",
              "      <th>P@1000_Okapi</th>\n",
              "      <th>P@5_Scratch</th>\n",
              "      <th>P@10_Scratch</th>\n",
              "      <th>P@15_Scratch</th>\n",
              "      <th>P@20_Scratch</th>\n",
              "      <th>P@30_Scratch</th>\n",
              "      <th>P@100_Scratch</th>\n",
              "      <th>P@200_Scratch</th>\n",
              "      <th>P@500_Scratch</th>\n",
              "      <th>P@1000_Scratch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.410526</td>\n",
              "      <td>0.369737</td>\n",
              "      <td>0.314035</td>\n",
              "      <td>0.283553</td>\n",
              "      <td>0.239035</td>\n",
              "      <td>0.147237</td>\n",
              "      <td>0.105132</td>\n",
              "      <td>0.060947</td>\n",
              "      <td>0.038000</td>\n",
              "      <td>0.423684</td>\n",
              "      <td>0.356579</td>\n",
              "      <td>0.327193</td>\n",
              "      <td>0.289474</td>\n",
              "      <td>0.241228</td>\n",
              "      <td>0.149079</td>\n",
              "      <td>0.105921</td>\n",
              "      <td>0.061632</td>\n",
              "      <td>0.038105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.291926</td>\n",
              "      <td>0.252465</td>\n",
              "      <td>0.209922</td>\n",
              "      <td>0.193630</td>\n",
              "      <td>0.166568</td>\n",
              "      <td>0.113356</td>\n",
              "      <td>0.083570</td>\n",
              "      <td>0.052218</td>\n",
              "      <td>0.032844</td>\n",
              "      <td>0.293879</td>\n",
              "      <td>0.239074</td>\n",
              "      <td>0.215868</td>\n",
              "      <td>0.198211</td>\n",
              "      <td>0.167320</td>\n",
              "      <td>0.110395</td>\n",
              "      <td>0.082546</td>\n",
              "      <td>0.051723</td>\n",
              "      <td>0.032929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.022000</td>\n",
              "      <td>0.012750</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.060000</td>\n",
              "      <td>0.043750</td>\n",
              "      <td>0.022000</td>\n",
              "      <td>0.012750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>0.048000</td>\n",
              "      <td>0.029500</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.087500</td>\n",
              "      <td>0.049000</td>\n",
              "      <td>0.029500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.412500</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.192500</td>\n",
              "      <td>0.135000</td>\n",
              "      <td>0.082500</td>\n",
              "      <td>0.049250</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>0.202500</td>\n",
              "      <td>0.141250</td>\n",
              "      <td>0.085000</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.566667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.218000</td>\n",
              "      <td>0.134000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>0.202000</td>\n",
              "      <td>0.134000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7b5fb9e-7129-45e4-810a-96e11297cf5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7b5fb9e-7129-45e4-810a-96e11297cf5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7b5fb9e-7129-45e4-810a-96e11297cf5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalized Discounted Cumulative Gain"
      ],
      "metadata": {
        "id": "rbP6L_hvq7g1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ndcg_cols = [\n",
        "    'NDCG@5',\n",
        "    'NDCG@10',\n",
        "    'NDCG@15',\n",
        "    'NDCG@20',\n",
        "    'NDCG@30',\n",
        "    'NDCG@100',\n",
        "    'NDCG@200',\n",
        "    'NDCG@500',\n",
        "    'NDCG@1000'\n",
        "]"
      ],
      "metadata": {
        "id": "rqPldUlKIGhT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics_1[ndcg_cols].describe().merge(\n",
        "    df_metrics_2[ndcg_cols].describe(), \n",
        "    how='left', \n",
        "    left_index=True, \n",
        "    right_index=True, \n",
        "    suffixes=('_Okapi', '_Scratch')\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "rFUJ05xLJxo4",
        "outputId": "efd6e9df-6195-42b7-f462-5b635474a154"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       NDCG@5_Okapi  NDCG@10_Okapi  NDCG@15_Okapi  NDCG@20_Okapi  \\\n",
              "count     76.000000      76.000000      76.000000      76.000000   \n",
              "mean       0.437259       0.407284       0.377304       0.362763   \n",
              "std        0.304352       0.260309       0.223411       0.210981   \n",
              "min        0.000000       0.000000       0.000000       0.000000   \n",
              "25%        0.169580       0.219384       0.203825       0.202789   \n",
              "50%        0.426966       0.396891       0.381293       0.334246   \n",
              "75%        0.684352       0.608999       0.550456       0.533233   \n",
              "max        1.000000       0.936379       0.864362       0.879198   \n",
              "\n",
              "       NDCG@30_Okapi  NDCG@100_Okapi  NDCG@200_Okapi  NDCG@500_Okapi  \\\n",
              "count      76.000000       76.000000       76.000000       76.000000   \n",
              "mean        0.345349        0.387496        0.450308        0.532110   \n",
              "std         0.197175        0.195955        0.188573        0.177706   \n",
              "min         0.000000        0.075815        0.136392        0.191298   \n",
              "25%         0.200805        0.252744        0.332118        0.425279   \n",
              "50%         0.345198        0.356438        0.431062        0.533139   \n",
              "75%         0.500274        0.539224        0.571030        0.665318   \n",
              "max         0.912788        0.912788        0.912788        0.912788   \n",
              "\n",
              "       NDCG@1000_Okapi  NDCG@5_Scratch  NDCG@10_Scratch  NDCG@15_Scratch  \\\n",
              "count        76.000000       76.000000        76.000000        76.000000   \n",
              "mean          0.591084        0.446872         0.399259         0.382963   \n",
              "std           0.168439        0.308564         0.254274         0.229491   \n",
              "min           0.192022        0.000000         0.000000         0.000000   \n",
              "25%           0.500071        0.169580         0.209938         0.202881   \n",
              "50%           0.623669        0.477797         0.406278         0.381447   \n",
              "75%           0.715886        0.684352         0.602245         0.571163   \n",
              "max           0.945759        1.000000         0.933746         0.861179   \n",
              "\n",
              "       NDCG@20_Scratch  NDCG@30_Scratch  NDCG@100_Scratch  NDCG@200_Scratch  \\\n",
              "count        76.000000        76.000000         76.000000         76.000000   \n",
              "mean          0.364100         0.343428          0.388335          0.451207   \n",
              "std           0.217347         0.199925          0.193561          0.188291   \n",
              "min           0.000000         0.000000          0.076309          0.121592   \n",
              "25%           0.211868         0.209567          0.250900          0.326761   \n",
              "50%           0.359974         0.339945          0.363492          0.421079   \n",
              "75%           0.531985         0.479205          0.521657          0.580309   \n",
              "max           0.804155         0.897710          0.897710          0.897710   \n",
              "\n",
              "       NDCG@500_Scratch  NDCG@1000_Scratch  \n",
              "count         76.000000          76.000000  \n",
              "mean           0.535172           0.591227  \n",
              "std            0.180216           0.171697  \n",
              "min            0.187927           0.193426  \n",
              "25%            0.400283           0.491053  \n",
              "50%            0.547889           0.626217  \n",
              "75%            0.671344           0.709674  \n",
              "max            0.914870           0.930482  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9cffe52-f43a-47f1-829e-4e7cb133ca84\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NDCG@5_Okapi</th>\n",
              "      <th>NDCG@10_Okapi</th>\n",
              "      <th>NDCG@15_Okapi</th>\n",
              "      <th>NDCG@20_Okapi</th>\n",
              "      <th>NDCG@30_Okapi</th>\n",
              "      <th>NDCG@100_Okapi</th>\n",
              "      <th>NDCG@200_Okapi</th>\n",
              "      <th>NDCG@500_Okapi</th>\n",
              "      <th>NDCG@1000_Okapi</th>\n",
              "      <th>NDCG@5_Scratch</th>\n",
              "      <th>NDCG@10_Scratch</th>\n",
              "      <th>NDCG@15_Scratch</th>\n",
              "      <th>NDCG@20_Scratch</th>\n",
              "      <th>NDCG@30_Scratch</th>\n",
              "      <th>NDCG@100_Scratch</th>\n",
              "      <th>NDCG@200_Scratch</th>\n",
              "      <th>NDCG@500_Scratch</th>\n",
              "      <th>NDCG@1000_Scratch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>76.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.437259</td>\n",
              "      <td>0.407284</td>\n",
              "      <td>0.377304</td>\n",
              "      <td>0.362763</td>\n",
              "      <td>0.345349</td>\n",
              "      <td>0.387496</td>\n",
              "      <td>0.450308</td>\n",
              "      <td>0.532110</td>\n",
              "      <td>0.591084</td>\n",
              "      <td>0.446872</td>\n",
              "      <td>0.399259</td>\n",
              "      <td>0.382963</td>\n",
              "      <td>0.364100</td>\n",
              "      <td>0.343428</td>\n",
              "      <td>0.388335</td>\n",
              "      <td>0.451207</td>\n",
              "      <td>0.535172</td>\n",
              "      <td>0.591227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.304352</td>\n",
              "      <td>0.260309</td>\n",
              "      <td>0.223411</td>\n",
              "      <td>0.210981</td>\n",
              "      <td>0.197175</td>\n",
              "      <td>0.195955</td>\n",
              "      <td>0.188573</td>\n",
              "      <td>0.177706</td>\n",
              "      <td>0.168439</td>\n",
              "      <td>0.308564</td>\n",
              "      <td>0.254274</td>\n",
              "      <td>0.229491</td>\n",
              "      <td>0.217347</td>\n",
              "      <td>0.199925</td>\n",
              "      <td>0.193561</td>\n",
              "      <td>0.188291</td>\n",
              "      <td>0.180216</td>\n",
              "      <td>0.171697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075815</td>\n",
              "      <td>0.136392</td>\n",
              "      <td>0.191298</td>\n",
              "      <td>0.192022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076309</td>\n",
              "      <td>0.121592</td>\n",
              "      <td>0.187927</td>\n",
              "      <td>0.193426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.169580</td>\n",
              "      <td>0.219384</td>\n",
              "      <td>0.203825</td>\n",
              "      <td>0.202789</td>\n",
              "      <td>0.200805</td>\n",
              "      <td>0.252744</td>\n",
              "      <td>0.332118</td>\n",
              "      <td>0.425279</td>\n",
              "      <td>0.500071</td>\n",
              "      <td>0.169580</td>\n",
              "      <td>0.209938</td>\n",
              "      <td>0.202881</td>\n",
              "      <td>0.211868</td>\n",
              "      <td>0.209567</td>\n",
              "      <td>0.250900</td>\n",
              "      <td>0.326761</td>\n",
              "      <td>0.400283</td>\n",
              "      <td>0.491053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.426966</td>\n",
              "      <td>0.396891</td>\n",
              "      <td>0.381293</td>\n",
              "      <td>0.334246</td>\n",
              "      <td>0.345198</td>\n",
              "      <td>0.356438</td>\n",
              "      <td>0.431062</td>\n",
              "      <td>0.533139</td>\n",
              "      <td>0.623669</td>\n",
              "      <td>0.477797</td>\n",
              "      <td>0.406278</td>\n",
              "      <td>0.381447</td>\n",
              "      <td>0.359974</td>\n",
              "      <td>0.339945</td>\n",
              "      <td>0.363492</td>\n",
              "      <td>0.421079</td>\n",
              "      <td>0.547889</td>\n",
              "      <td>0.626217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.684352</td>\n",
              "      <td>0.608999</td>\n",
              "      <td>0.550456</td>\n",
              "      <td>0.533233</td>\n",
              "      <td>0.500274</td>\n",
              "      <td>0.539224</td>\n",
              "      <td>0.571030</td>\n",
              "      <td>0.665318</td>\n",
              "      <td>0.715886</td>\n",
              "      <td>0.684352</td>\n",
              "      <td>0.602245</td>\n",
              "      <td>0.571163</td>\n",
              "      <td>0.531985</td>\n",
              "      <td>0.479205</td>\n",
              "      <td>0.521657</td>\n",
              "      <td>0.580309</td>\n",
              "      <td>0.671344</td>\n",
              "      <td>0.709674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.936379</td>\n",
              "      <td>0.864362</td>\n",
              "      <td>0.879198</td>\n",
              "      <td>0.912788</td>\n",
              "      <td>0.912788</td>\n",
              "      <td>0.912788</td>\n",
              "      <td>0.912788</td>\n",
              "      <td>0.945759</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.933746</td>\n",
              "      <td>0.861179</td>\n",
              "      <td>0.804155</td>\n",
              "      <td>0.897710</td>\n",
              "      <td>0.897710</td>\n",
              "      <td>0.897710</td>\n",
              "      <td>0.914870</td>\n",
              "      <td>0.930482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9cffe52-f43a-47f1-829e-4e7cb133ca84')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9cffe52-f43a-47f1-829e-4e7cb133ca84 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9cffe52-f43a-47f1-829e-4e7cb133ca84');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recuperando documentos baseado na query do usuário\n",
        "\n",
        "Também já a opção do usuário submeter uma query e recuperar um set de N documentos que os algoritimos deram match. Para isso, basta usar o método `retrieve_docs_from_query` informando a query e o número de documentos a serem recuperados."
      ],
      "metadata": {
        "id": "_l7JKfY2FOa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining query\n",
        "query = '''\n",
        "What problems and concerns are there in making up descriptive titles? \n",
        "What difficulties are involved in automatically retrieving articles from approximate titles? \n",
        "What is the usual relevance of the content of articles to their titles?'''\n",
        "\n",
        "# Retrieving documents for both algorithm implementations \n",
        "retrieved_docs_1 = search_engine_1.retrieve_docs_from_query(query, n=10)\n",
        "retrieved_docs_2 = search_engine_2.retrieve_docs_from_query(query, n=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8s_6Wn5rCtF",
        "outputId": "9e8bdd7e-543f-494d-b77d-f1e79160444f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function 'retrieve_docs_from_query' executed in 0.0142s\n",
            "Function '_fit' executed in 0.0555s\n",
            "Function 'retrieve_docs_from_query' executed in 0.0623s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Número de documentos recuperados:', len(retrieved_docs_1))\n",
        "print('Melhor match:', retrieved_docs_1[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7niuiFwGacs",
        "outputId": "096c1be1-c2c1-49e8-992c-15b29e07fff1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de documentos recuperados: 10\n",
            "Melhor match: The Information Content of Titles in Engineering Literature Bottle, Robert T. Since many alerting and information services rely very heavily on the use of titles to transfer information to the potential user, it is essential that he be aware of the proportion of the information contained in the complete document which will not be deducible from the title and which he will therefore miss.. Methods will be discussed for analyzing the relative information content of the titles of engineering paper and results presented for the amount and type of information lost through scanning title listing only.. Between one-third and one-half of indexable terms are not retrievable from article titles even if all possible synonyms and  related terms are used.. If all synonyms are used instead of one keyword the amount of information retrieved is increased by about 70 percent.. The problems of dealing with synonyms and with syntactical variants in searching titles indexes are discussed.. The possibility of using keywords in journal titles as supplementary retrieval tags is suggested since they were deemed useful in nearly one-third of the sample of papers analyzed.. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Número de documentos recuperados:', len(retrieved_docs_2))\n",
        "print('Melhor match:', retrieved_docs_2[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He5UMySGGcHW",
        "outputId": "ee5b722e-af50-43da-f352-ba46a21cde4b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de documentos recuperados: 10\n",
            "Melhor match: The Information Content of Titles in Engineering Literature Bottle, Robert T. Since many alerting and information services rely very heavily on the use of titles to transfer information to the potential user, it is essential that he be aware of the proportion of the information contained in the complete document which will not be deducible from the title and which he will therefore miss.. Methods will be discussed for analyzing the relative information content of the titles of engineering paper and results presented for the amount and type of information lost through scanning title listing only.. Between one-third and one-half of indexable terms are not retrievable from article titles even if all possible synonyms and  related terms are used.. If all synonyms are used instead of one keyword the amount of information retrieved is increased by about 70 percent.. The problems of dealing with synonyms and with syntactical variants in searching titles indexes are discussed.. The possibility of using keywords in journal titles as supplementary retrieval tags is suggested since they were deemed useful in nearly one-third of the sample of papers analyzed.. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bMZ7TTnlGcww"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}